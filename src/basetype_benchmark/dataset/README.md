# Gestion des Datasets

Ce rÃ©pertoire contient les outils pour gÃ©nÃ©rer, gÃ©rer et distribuer les datasets du benchmark.

## Architecture

```
dataset_gen/
â”œâ”€â”€ config.py          # Configuration des profils de gÃ©nÃ©ration
â”œâ”€â”€ generator.py       # GÃ©nÃ©rateur de datasets synthÃ©tiques
â”œâ”€â”€ model.py           # ModÃ¨le de donnÃ©es
â”œâ”€â”€ export_*.py        # Exporteurs (PostgreSQL, Graph, RDF)
â”œâ”€â”€ dataset_manager.py # Gestionnaire de cache et export
â”œâ”€â”€ release_manager.py # Gestionnaire de releases GitHub
â”œâ”€â”€ workflow.py        # Workflow optimisÃ© pour Codespace
â”œâ”€â”€ orchestrator.py    # Orchestrateur automatique des benchmarks
â”œâ”€â”€ pregenerate.py     # PrÃ©-gÃ©nÃ©ration des datasets
â””â”€â”€ run.py            # Interface simple
```

## ğŸ¯ Vision GÃ©nÃ©rale

### Phase 1: GÃ©nÃ©ration des Datasets
- **GÃ©nÃ©ration sÃ©quentielle** avec stockage GitHub
- **36 profils** : 3 Ã©chelles Ã— 4 durÃ©es Ã— 3 formats
- **Stockage optimisÃ©** : pas de stockage local permanent

### Phase 2: Orchestration Automatique
- **SÃ©quence automatique** : upload â†’ container â†’ benchmark â†’ nettoyage
- **3 modÃ¨les** : PostgreSQL, Memgraph, Oxigraph
- **MÃ©triques** : performance, mÃ©moire, temps d'exÃ©cution
- **Rapport final** consolidÃ©

## ğŸš€ Workflow Complet

### 1. PrÃ©paration des Datasets
```bash
cd /workspaces/baseTypeBenchmark/dataset_gen

# SÃ©lection intelligente selon stockage disponible
python workflow.py smart-select 10

# GÃ©nÃ©ration sÃ©quentielle avec nettoyage automatique
python workflow.py sequential small-1w small-1m medium-1w
```

### 2. Suite de Benchmarks AutomatisÃ©e
```bash
# ExÃ©cute TOUS les tests automatiquement
python orchestrator.py full-suite

# OU test individuel pour debug
python orchestrator.py single small-1w postgres
```

### 3. Analyse des RÃ©sultats
```bash
# RÃ©sultats dÃ©taillÃ©s
cat results/benchmark_results.json

# Rapport consolidÃ©
cat results/benchmark_report.md
```

## ğŸ“Š Couverture des Tests

### ModÃ¨les TestÃ©s
- **ğŸ˜ PostgreSQL** : TimescaleDB pour sÃ©ries temporelles
- **ğŸ•¸ï¸ Memgraph** : Property Graph en mÃ©moire
- **ğŸ—‚ï¸ Oxigraph** : RDF/SPARQL

### Profils de Charge
| Ã‰chelle | Points | DurÃ©e | Exemple |
|---------|--------|-------|---------|
| **SMALL** | 50k | 1w/1m/6m/1y | BÃ¢timent moyen |
| **MEDIUM** | 100k | 1w/1m/6m/1y | Grand bÃ¢timent |
| **LARGE** | 500k | 1w/1m/6m/1y | Campus/ensemble |

**Total : 36 combinaisons Ã— 3 modÃ¨les = 108 tests**

## âš™ï¸ Orchestration Technique

### SÃ©quence par Test
1. **ğŸ“¥ TÃ©lÃ©chargement** : Dataset depuis GitHub Release
2. **ğŸ³ Container** : DÃ©marrage du service appropriÃ©
3. **ğŸ“¤ Chargement** : Import des donnÃ©es
4. **âš¡ Benchmark** : ExÃ©cution des 8 queries
5. **ğŸ“Š MÃ©triques** : Collecte performance/mÃ©moire
6. **ğŸ§¹ Nettoyage** : ArrÃªt container + suppression donnÃ©es

### MÃ©triques CollectÃ©es
- **Temps d'exÃ©cution** par query
- **Utilisation mÃ©moire** peak
- **Temps de chargement** des donnÃ©es
- **Taux de succÃ¨s** des opÃ©rations

## ğŸ’¾ Gestion du Volume pour Codespace

### ProblÃ¨me RÃ©solu
- **Total thÃ©orique** : ~1 TB (tous datasets)
- **Limite Codespace** : 128 GB max
- **Solution** : TÃ©lÃ©chargement Ã  la demande

### Charge RÃ©elle par Test
| Profil | Archive | Format Max | RAM Peak |
|--------|---------|------------|----------|
| small-1w | 0.5 GB | 1 GB | **1 GB** |
| medium-1m | 4 GB | 8 GB | **8 GB** |
| large-1y | 50 GB | 500 GB | **50 GB** |

**âœ… Tests faisables mÃªme sur 16 GB RAM !**

## ğŸ”§ Configuration

### Variables d'Environnement
```bash
# Token GitHub pour les datasets
export GITHUB_TOKEN=your_token

# Timeout des services (secondes)
export SERVICE_TIMEOUT=60

# Nettoyage automatique
export CLEANUP_AFTER_TEST=true
```

### Docker Compose
Les services sont dÃ©finis dans `docker-compose.yml` Ã  la racine :
- `postgres` : PostgreSQL + TimescaleDB
- `memgraph` : Property Graph
- `oxigraph` : RDF/SPARQL

## ğŸ“ˆ RÃ©sultats et Rapports

### Structure des RÃ©sultats
```
results/
â”œâ”€â”€ benchmark_results.json    # RÃ©sultats dÃ©taillÃ©s JSON
â””â”€â”€ benchmark_report.md       # Rapport consolidÃ© Markdown
```

### MÃ©triques par ModÃ¨le
- **PostgreSQL** : Temps queries SQL, index performance
- **Memgraph** : Temps traversÃ©es graphe, mÃ©moire cache
- **Oxigraph** : Temps SPARQL, optimisation RDF

### Comparaisons
- **Performance relative** entre modÃ¨les
- **ScalabilitÃ©** selon la taille des donnÃ©es
- **EfficacitÃ© mÃ©moire** par paradigme

## ğŸš¦ Ã‰tats et Commandes

### PrÃ©paration
```bash
# VÃ©rifier stockage
python workflow.py storage

# Lister profils disponibles
python orchestrator.py list

# Test connexion GitHub
python workflow.py session small-1w
```

### ExÃ©cution
```bash
# Suite complÃ¨te (108 tests)
python orchestrator.py full-suite

# Test rapide (debug)
python orchestrator.py single small-1w postgres

# ArrÃªt manuel
docker-compose down
```

### Monitoring
```bash
# Suivre les rÃ©sultats
tail -f results/benchmark_results.json

# VÃ©rifier containers
docker ps

# Logs services
docker-compose logs postgres
```

## ğŸ” Debugging

### Tests Individuels
```bash
# Tester seulement le chargement
python workflow.py session small-1w

# Tester un container seul
docker-compose up -d postgres
docker-compose logs postgres

# Test de chargement manuel
python orchestrator.py single small-1w postgres
```

### ProblÃ¨mes Courants
1. **Timeout service** : Augmenter `SERVICE_TIMEOUT`
2. **MÃ©moire insuffisante** : Commencer par `small-1w`
3. **Rate limiting GitHub** : Pauses entre tÃ©lÃ©chargements
4. **Espace disque** : Nettoyage automatique activÃ©

## ğŸ¯ Prochaines Ã‰tapes

1. **Phase 1** âœ… : Architecture dataset + workflow optimisÃ©
2. **Phase 2** ğŸ”„ : ImplÃ©mentation orchestrateur (en cours)
3. **Phase 3** ğŸ“‹ : Tests pilotes sur small-1w
4. **Phase 4** ğŸ“Š : Suite complÃ¨te + analyse rÃ©sultats
5. **Phase 5** ğŸ“ˆ : Optimisations et comparaisons dÃ©taillÃ©es

---

**ğŸ‰ PrÃªt pour la rÃ©volution des benchmarks !**
